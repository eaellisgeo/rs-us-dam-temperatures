{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## This code is used for the analysis of river surface temperature profiles in CONUS 2013-2024 ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from shapely.geometry import Point, Polygon\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import linregress\n",
    "import pymannkendall as mk\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "########### Pull in the initial datasets ############\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Pull in the Dam File ###\n",
    "Dams = gpd.read_file(r\"F:\\Insert_File_Path_of_Shapefile_with_Dam_Locations.shp\") # Update this file path\n",
    "## This Shapefile ^^ has all the dams used to pull temperatures in it with infromation from HILARRI matched to it (completed in ArcGIS) ##\n",
    "Dams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pull in the Temperature Data -- Up/Ds FIltering ###\n",
    "# Set up the location of the data\n",
    "FilePath = r\"F:\\Insert_File_Path_for_Folder_of_Snapped_Temperatures_for_Each_Dam\" ## Temperatures for each dam\n",
    "\n",
    "# Get the List of Monthly Data\n",
    "CSVFiles = glob.glob(os.path.join(FilePath, \"*Avg_Img_Temps.csv\")) \n",
    "\n",
    "# Loop through the files for each dam and make one dataframe\n",
    "All_Mo_Avg = pd.DataFrame()\n",
    "for i in range(len(CSVFiles)):\n",
    "    try:\n",
    "        x = pd.read_csv(CSVFiles[i], engine='python')\n",
    "        All_Mo_Avg = pd.concat([All_Mo_Avg,x],axis=0)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(CSVFiles[i], \" is empty and has been skipped.\") # In case some of the CSV files are empty\n",
    "# Preview the data\n",
    "All_Mo_Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Looking at just the wide points, and non dam points\n",
    "All_Mo_Avg_Subset = All_Mo_Avg[(All_Mo_Avg['Avg_RWC_Wid'] >= 100) & (All_Mo_Avg['Up_Ds']!= 'Dam')]\n",
    "All_Mo_Avg_Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Clean up the Data ####\n",
    "# Get Dam Info on the nodes/temperature Values  and clean up the dataset ##\n",
    "HydroPower = pd.merge(All_Mo_Avg_Subset, Dams[['grod_id', 'dataset']], left_on = 'Assgn_dam', right_on = 'grod_id' , how='left').drop(columns = [ 'grod_id'])\n",
    "\n",
    "# Remove Unwanted Columns\n",
    "HydroDams_Clean = HydroPower.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Make an easier code for hydropower variables -- Updating the dictionary for simplicity\n",
    "damtype_dict = {'Hydropower dam associated with power plant; no reservoir': 'HDNR', 'Hydropower dam associated with reservoir and power plant': 'HDR', 'Hydropower dam only; no reservoir or power plant': 'HDNR','Hydropower dam associated with reservoir; no power plant':'HDR', None: 'NoHydro'} # dictionary\n",
    "HydroDams_Clean['HydroCode'] = HydroDams_Clean['dataset'].map(damtype_dict)  # apply dictionary\n",
    "\n",
    "# Group datata into distance bins\n",
    "bins = np.arange(-100, 100, 2).tolist() # create 2km bins\n",
    "HydroDams_Clean['Bins'] = pd.cut(HydroDams_Clean['Dam_Dist_km'], bins) # apply bins\n",
    "\n",
    "# Create a Code to easily group based on Up/Ds and Lake Flag\n",
    "HydroDams_Clean['Up_Ds_Grp']  = np.nan\n",
    "HydroDams_Clean['Up_Ds_Grp'] = np.where((HydroDams_Clean['Up_Ds'] == 'Downstream') & (HydroDams_Clean['lakeflag'] == 0) , 'Downstream River', HydroDams_Clean['Up_Ds_Grp'])\n",
    "HydroDams_Clean['Up_Ds_Grp'] = np.where((HydroDams_Clean['Up_Ds'] == 'Downstream') & (HydroDams_Clean['lakeflag'] > 0) , 'Downstream Reservoir', HydroDams_Clean['Up_Ds_Grp'])\n",
    "HydroDams_Clean['Up_Ds_Grp'] = np.where((HydroDams_Clean['Up_Ds'] == 'Upstream') & (HydroDams_Clean['lakeflag'] == 0) , 'Upstream River', HydroDams_Clean['Up_Ds_Grp'])\n",
    "HydroDams_Clean['Up_Ds_Grp'] = np.where((HydroDams_Clean['Up_Ds'] == 'Upstream') & (HydroDams_Clean['lakeflag'] > 0) , 'Upstream Reservoir', HydroDams_Clean['Up_Ds_Grp'])\n",
    "\n",
    "# Preview Data\n",
    "HydroDams_Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "############## FILTER TO UNIQUE, USABLE PROFILES ##############\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Profiles -- Where there are river nodes upstream ##\n",
    "UpRiver= HydroDams_Clean[(HydroDams_Clean[\"Up_Ds_Grp\"] == \"Upstream River\")]\n",
    "UpRiver_grp = UpRiver.groupby(['Month','Day','Year','Assgn_dam']).agg({'Join_Node': ['count']})\n",
    "UpRiver_grp.columns = [\"NodeCount\"]\n",
    "UpRiver_grp = UpRiver_grp.reset_index()\n",
    "\n",
    "## Identify Profiles with 5 Upstream River Nodes\n",
    "DamTemps_RivUp = UpRiver_grp[UpRiver_grp[\"NodeCount\"]>= 5]\n",
    "\n",
    "## Get Profiles -- Where there are river nodes directly downstream from the dam ##\n",
    "DsRiver= HydroDams_Clean[(HydroDams_Clean[\"Up_Ds_Grp\"] == \"Downstream River\") & (HydroDams_Clean[\"Dam_Dist_km\"] <= 20)]\n",
    "DsRiver_grp = DsRiver.groupby(['Month','Day','Year','Assgn_dam']).agg({'Join_Node': ['count']})\n",
    "DsRiver_grp.columns = [\"NodeCount\"]\n",
    "DsRiver_grp = DsRiver_grp.reset_index()\n",
    "\n",
    "## Identify Profiles with 5 Downstream River Nodes\n",
    "DamTemps_RivDs = DsRiver_grp[DsRiver_grp[\"NodeCount\"]>= 5]\n",
    "\n",
    "#### NUMBER OF PROFILES ####\n",
    "UpAnDown = pd.merge(DamTemps_RivDs, DamTemps_RivUp, on = ['Assgn_dam', \"Month\", \"Day\", \"Year\"] , how='inner')\n",
    "UpAnDown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the unique profiles with enough points to a CSV\n",
    "UpAnDown.to_csv(r\"F:\\Insert_File_Output_Path\\List_of_Profiles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "############ Identify Profiles with Significant Up/DS Differences ##############\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Profile Points (filtering only 20km DS)##\n",
    "DamTemps_Riv20 = HydroDams_Clean[(HydroDams_Clean[\"Dam_Dist_km\"] <= 20)]\n",
    "\n",
    "## Calculate Significance (Up River/20km)##\n",
    "col_names =  ['Assgn_dam','Month','Day','Year', 'KW_Pval']\n",
    "KW_Prof_Results_Riv20  = pd.DataFrame(columns = col_names)\n",
    "Unique_Profiles_Riv20 =  UpAnDown[[\"Assgn_dam\", \"Month\",\"Day\", \"Year\"]]\n",
    "\n",
    "for i in range(len(Unique_Profiles_Riv20)):  # For selecting -- .iloc[i, 0] ## i for row , Dam Number (0), Month (1), Day (2), Year(3)\n",
    "    # Set up the subsets for comparison -- All\n",
    "    KruskalTest_1 = DamTemps_Riv20[(DamTemps_Riv20['Assgn_dam'] == Unique_Profiles_Riv20.iloc[i, 0]) & (DamTemps_Riv20['Month'] == Unique_Profiles_Riv20.iloc[i, 1]) & (DamTemps_Riv20['Day'] == Unique_Profiles_Riv20.iloc[i, 2]) & (DamTemps_Riv20['Year'] == Unique_Profiles_Riv20.iloc[i, 3]) & (DamTemps_Riv20['Up_Ds_Grp'] == \"Downstream River\")].Avg_Temp.tolist() # Downstream\n",
    "    KruskalTest_2 = DamTemps_Riv20[(DamTemps_Riv20['Assgn_dam'] == Unique_Profiles_Riv20.iloc[i, 0]) & (DamTemps_Riv20['Month'] == Unique_Profiles_Riv20.iloc[i, 1]) & (DamTemps_Riv20['Day'] == Unique_Profiles_Riv20.iloc[i, 2]) & (DamTemps_Riv20['Year'] == Unique_Profiles_Riv20.iloc[i, 3]) & (DamTemps_Riv20['Up_Ds_Grp'] == \"Upstream River\")].Avg_Temp.tolist() # Upstream    \n",
    "     \n",
    "    # Run the test -- River vs DS\n",
    "    h_statistic, p_value = stats.kruskal(KruskalTest_2,KruskalTest_1)\n",
    "\n",
    "    # Get Dictionary\n",
    "    dictionary = {'Assgn_dam': Unique_Profiles_Riv20.iloc[i, 0], 'Month': Unique_Profiles_Riv20.iloc[i, 1], 'Day': Unique_Profiles_Riv20.iloc[i, 2], 'Year': Unique_Profiles_Riv20.iloc[i, 3], 'KW_Pval': [p_value]}\n",
    "\n",
    "    df_dictionary = pd.DataFrame.from_dict(dictionary)\n",
    "    \n",
    "    # Add to DF\n",
    "    output = pd.concat([KW_Prof_Results_Riv20, df_dictionary], ignore_index=True)\n",
    "    \n",
    "    KW_Prof_Results_Riv20 = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Profiles with >=5 Riv Nodes Upstream and Downstream: \", len(Unique_Profiles_Riv20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Significant profiles (Riv Up/20km)\n",
    "KW_Prof_Results_Riv20['KW_Sig_10'] = np.where((KW_Prof_Results_Riv20['KW_Pval'] <= 0.1), 'Significant', 'Not Significant')\n",
    "KW_Prof_Results_Riv20['KW_Sig_05'] = np.where((KW_Prof_Results_Riv20['KW_Pval'] <= 0.05), 'Significant', 'Not Significant')\n",
    "KW_Prof_Results_Riv20['KW_Sig_01'] = np.where((KW_Prof_Results_Riv20['KW_Pval'] <= 0.01), 'Significant', 'Not Significant')\n",
    "KW_Prof_Results_Riv20['KW_Sig_001'] = np.where((KW_Prof_Results_Riv20['KW_Pval'] <= 0.001), 'Significant', 'Not Significant')\n",
    "KW_Prof_Results_Riv20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Significant Profiles within 20km\n",
    "Signif_Riv20_Profiles = KW_Prof_Results_Riv20[KW_Prof_Results_Riv20[\"KW_Sig_05\"] == \"Significant\"]\n",
    "print(\"Number of Profiles with Signficant differences Up/Ds: \", len(Signif_Riv20_Profiles))\n",
    "\n",
    "### Percent Significant ### \n",
    "print(\"Percent Significant Profiles: \", round((len(Signif_Riv20_Profiles)/len(Unique_Profiles_Riv20))*100), \"%\")\n",
    "\n",
    "# Get Relevant nodes\n",
    "Signif_Riv20_Profile_Nodes = pd.merge(DamTemps_Riv20, Signif_Riv20_Profiles, on=['Month', 'Day','Year','Assgn_dam'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Not Significant Profiles within 20km\n",
    "NS_Riv20_Profiles = KW_Prof_Results_Riv20[KW_Prof_Results_Riv20[\"KW_Sig_05\"] == \"Not Significant\"]\n",
    "\n",
    "# Get Relevant nodes\n",
    "NS_Riv20_Profile_Nodes = pd.merge(DamTemps_Riv20, NS_Riv20_Profiles, on=['Month', 'Day','Year','Assgn_dam'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the Results ## \n",
    "KW_Prof_Results_Riv20.to_csv(r\"F:\\Insert_File_Output_for_Significance_Results.csv\") # Update this file path\n",
    "Signif_Riv20_Profile_Nodes.to_csv(r\"F:\\Insert_File_Output_for_Significant_nodes.csv\") # Update this file path\n",
    "NS_Riv20_Profile_Nodes.to_csv(r\"F:\\Insert_File_Output_for_Nonsignificant_nodes.csv\") # Update this file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "########### Get Average Temperature Differences ################\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the Avg Diff Value for the profiles  ##\n",
    "# Get the Profiles and Nodes -- Copy\n",
    "SignificantProfiles_Riv = Signif_Riv20_Profiles\n",
    "SignificantProfiles_Riv_Nodes = Signif_Riv20_Profile_Nodes\n",
    "\n",
    "# Of The Significant Profiles -- Avg Diff Up Vs Ds \n",
    "Upstream_Riv = SignificantProfiles_Riv_Nodes[(SignificantProfiles_Riv_Nodes['Up_Ds_Grp'] == \"Upstream River\")]\n",
    "Upstream_Avgs_Riv = Upstream_Riv.groupby(['Month','Day','Year','Assgn_dam']).agg({'Avg_Temp': ['mean']})\n",
    "Upstream_Avgs_Riv.columns = ['Up_Avg']\n",
    "Upstream_Avgs_Riv = Upstream_Avgs_Riv.reset_index()\n",
    "\n",
    "# Downstream_Riv = SignificantProfiles_Riv_Nodes[(SignificantProfiles_Riv_Nodes['Up_Ds'] == 'Downstream')]\n",
    "Downstream_Riv = SignificantProfiles_Riv_Nodes[(SignificantProfiles_Riv_Nodes['Up_Ds_Grp'] == 'Downstream River')]\n",
    "Downstream_Avgs_Riv = Downstream_Riv.groupby(['Month','Day','Year','Assgn_dam']).agg({'Avg_Temp': ['mean']})\n",
    "Downstream_Avgs_Riv.columns = ['Ds_Avg']\n",
    "Downstream_Avgs_Riv = Downstream_Avgs_Riv.reset_index()\n",
    "\n",
    "Profile_Avgs_Riv = pd.merge(Upstream_Avgs_Riv, Downstream_Avgs_Riv, on=['Month','Day', 'Year','Assgn_dam'], how='outer' )\n",
    "\n",
    "Profile_Avgs_Riv['Temp_Diff'] = Profile_Avgs_Riv['Ds_Avg'] - Profile_Avgs_Riv['Up_Avg'] \n",
    "Profile_Avgs_Riv['Abs_Temp_Diff'] = abs(Profile_Avgs_Riv['Ds_Avg'] - Profile_Avgs_Riv['Up_Avg'])\n",
    "\n",
    "## Save the Results ## \n",
    "Profile_Avgs_Riv.to_csv(r\"F:\\Insert_File_Path_for_Signifcant_Profile_Averages.csv\") # Update this file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Warmer Profiles \n",
    "print(\"Number of Warmer Profiles: \" + str(len(Profile_Avgs_Riv[Profile_Avgs_Riv['Temp_Diff'] > 0])))\n",
    "print(\"Percent Warmer: \" + str(round((len(Profile_Avgs_Riv[Profile_Avgs_Riv['Temp_Diff'] > 0]) / len(Profile_Avgs_Riv)*100)))+ \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cooler Profiles\n",
    "print(\"Number of Cooler Profiles: \" + str(len(Profile_Avgs_Riv[Profile_Avgs_Riv['Temp_Diff'] < 0])))\n",
    "print(\"Percent Cooler: \" + str(round((len(Profile_Avgs_Riv[Profile_Avgs_Riv['Temp_Diff'] < 0]) / len(Profile_Avgs_Riv)*100)))+ \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at the differences seasonally ## \n",
    "Seasonal_Diffs = Profile_Avgs_Riv[:]\n",
    "\n",
    "# Assign seasons according to the months\n",
    "Seasonal_Diffs[\"Season\"] = np.nan\n",
    "Seasonal_Diffs[\"Season\"] = np.where(Seasonal_Diffs[\"Month\"].isin([12, 1, 2]), \"Winter\", Seasonal_Diffs[\"Season\"])\n",
    "Seasonal_Diffs[\"Season\"] = np.where(Seasonal_Diffs[\"Month\"].isin([3, 4, 5]), \"Spring\", Seasonal_Diffs[\"Season\"])\n",
    "Seasonal_Diffs[\"Season\"] = np.where(Seasonal_Diffs[\"Month\"].isin([6,7,8]), \"Summer\", Seasonal_Diffs[\"Season\"])\n",
    "Seasonal_Diffs[\"Season\"] = np.where(Seasonal_Diffs[\"Month\"].isin([9, 10, 11]), \"Fall\", Seasonal_Diffs[\"Season\"])\n",
    "\n",
    "# Get the Direction of the temperature change\n",
    "Seasonal_Diffs[\"Diff_Direction\"] = np.nan\n",
    "Seasonal_Diffs[\"Diff_Direction\"] = np.where((Seasonal_Diffs[\"Temp_Diff\"] < 0) , 'Cooler', Seasonal_Diffs[\"Diff_Direction\"])\n",
    "Seasonal_Diffs[\"Diff_Direction\"] = np.where((Seasonal_Diffs[\"Temp_Diff\"] > 0) , 'Warmer', Seasonal_Diffs[\"Diff_Direction\"])\n",
    "\n",
    "## Get the profile stats by season \n",
    "\n",
    "# create a range function\n",
    "def calculate_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "## Get Group Info\n",
    "Profile_Stats_Season = Seasonal_Diffs.groupby([\"Season\",\"Diff_Direction\"]).agg({'Temp_Diff':['count','mean', 'std', calculate_range]})\n",
    "Profile_Stats_Season.columns = ['Profile_Count','Avg_Diff', 'STDV', 'Range']\n",
    "Profile_Stats_Season = Profile_Stats_Season.reset_index()\n",
    "\n",
    "## Save File \n",
    "Profile_Stats_Season.to_csv(r\"F:\\Insert_File_Path_for_Profile_Stats_by_Season.csv\") # Update this file path\n",
    "\n",
    "# Preview --- Table S3\n",
    "Profile_Stats_Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "############## Calculate the Profile Anomalies ##################\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## By Dam: Annual Anomalies ## -- Figure 4A\n",
    "# Get List of Dams that have at least one profile with 5 up and 5 down nodes\n",
    "Dams_with_Nodes = UpAnDown[\"Assgn_dam\"].drop_duplicates().to_list()\n",
    "Anom_Subset = HydroDams_Clean[HydroDams_Clean['Assgn_dam'].isin(Dams_with_Nodes)]\n",
    "\n",
    "# Get the average temperature for each month and dam\n",
    "Dam_Avg_All= Anom_Subset.groupby(['Assgn_dam','Year']).agg({'Avg_Temp': ['mean']})\n",
    "Dam_Avg_All.columns = ['Prof_Avg']\n",
    "Dam_Avg_All = Dam_Avg_All.reset_index()\n",
    "\n",
    "# Join the profile averages back to each node\n",
    "Dam_Anom_join_all = pd.merge(Anom_Subset, Dam_Avg_All, on=['Assgn_dam','Year'], how = 'left')\n",
    "\n",
    "# Calcuate the difference between the node value and the mean temperature for the given profile \n",
    "Dam_Anom_join_all['Temp_Anom'] = Dam_Anom_join_all['Avg_Temp'] - Dam_Anom_join_all['Prof_Avg']  ## Postive Values = warmer than the mean, Negative = colder than the mean \n",
    "\n",
    "# Remove Points far downstream\n",
    "Dam_Anom_join_all_sub = Dam_Anom_join_all[Dam_Anom_join_all['Dam_Dist_km'] <= 60]\n",
    "\n",
    "# Get the Average Anomalies for Each Dam (All)\n",
    "Avg_Anom_byDam_all = Dam_Anom_join_all_sub.groupby([\"Up_Ds_Grp\", \"Month\",\"Day\",\"Year\",\"Assgn_dam\"]).agg({'Temp_Anom':['mean','count']})\n",
    "Avg_Anom_byDam_all.columns = ['Anom_Avg', 'NPoints']\n",
    "Avg_Anom_byDam_all = Avg_Anom_byDam_all.reset_index()\n",
    "\n",
    "\n",
    "### Plot the Anomalies ###\n",
    "# Set the order of groups for boxplots\n",
    "grouporder = ['Upstream River', 'Upstream Reservoir', 'Downstream River']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6,4))\n",
    "ax = sns.boxplot(x=\"Month\", y=\"Anom_Avg\",\n",
    "                 hue = \"Up_Ds_Grp\", hue_order=grouporder,\n",
    "                 palette=\"winter_r\",\n",
    "                 linewidth=0.75,\n",
    "                 showfliers = False, # Comment this out to see outliers\n",
    "                 data =Avg_Anom_byDam_all, \n",
    "                 zorder = 3)\n",
    "ax.set_xlabel( \"Month\", fontsize=12) \n",
    "ax.set_ylabel( \"Average Temperature Anomaly (°C)\", fontsize=12) \n",
    "ax.tick_params(labelsize=12)\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(5))\n",
    "sns.move_legend(ax, title='', fontsize='8', loc =\"upper left\")\n",
    "plt.savefig(r\"F:\\Insert_File_Path_for_Anomalies_AtDam_Annual.png\", bbox_inches=\"tight\", pad_inches=0.25, dpi=1200) # Update this file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Variance and STDV ##\n",
    "# Get Values for Each Month\n",
    "Avg_Anom_STDV_Dam = Avg_Anom_byDam_all.groupby([\"Month\", \"Up_Ds_Grp\"]).agg({'Anom_Avg':['std','var']})\n",
    "Avg_Anom_STDV_Dam.columns = ['Anom_STDV', 'Anom_Var']\n",
    "Avg_Anom_STDV_Dam = Avg_Anom_STDV_Dam.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## By Profile: Spatial Anomalies ## -- Figure 4B\n",
    "# Get List of Dams that have at least one profile with 5 up and 5 down nodes\n",
    "Dams_with_Nodes = UpAnDown[\"Assgn_dam\"].drop_duplicates().to_list()\n",
    "Anom_Subset = HydroDams_Clean[HydroDams_Clean['Assgn_dam'].isin(Dams_with_Nodes)]\n",
    "\n",
    "# Get the average temperature for each profile\n",
    "Anom_grp = Anom_Subset.groupby(['Month','Day','Year','Assgn_dam']).agg({'Avg_Temp': ['mean']})\n",
    "Anom_grp.columns = ['Prof_Avg']\n",
    "Anom_grp = Anom_grp.reset_index()\n",
    "\n",
    "## Save the Spatial Average Profile Temperature\n",
    "Anom_grp.to_csv(r\"F:\\Insert_File_Path_for_All_Entire_Profile_Averages.csv\") # Update this file path\n",
    "\n",
    "# Join the profile averages back to each node\n",
    "Anom_join = pd.merge(Anom_Subset, Anom_grp, on=['Assgn_dam','Month','Day', 'Year'], how = 'left')\n",
    "\n",
    "# Calcuate the difference between the node value and the mean temperature for the given profile \n",
    "Anom_join['Temp_Anom'] = Anom_join['Avg_Temp'] - Anom_join['Prof_Avg']  ## Postive Values = warmer than the mean, Negative = colder than the mean \n",
    "\n",
    "# Remove Points far downstream\n",
    "Anom_join_sub = Anom_join[Anom_join['Dam_Dist_km'] <= 60]\n",
    "\n",
    "# Get the Average Anomalies for Each Profile and Group\n",
    "Avg_Anom_byDam = Anom_join_sub.groupby([\"Up_Ds_Grp\", \"Month\",\"Day\",\"Year\",\"Assgn_dam\"]).agg({'Temp_Anom':['mean','count']})\n",
    "Avg_Anom_byDam.columns = ['Anom_Avg', 'NPoints']\n",
    "Avg_Anom_byDam = Avg_Anom_byDam.reset_index()\n",
    "\n",
    "### Plot the Anomalies ### \n",
    "# Set the order of groups for boxplots\n",
    "grouporder = ['Upstream River', 'Upstream Reservoir', 'Downstream River']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6,4))\n",
    "ax = sns.boxplot(x=\"Month\", y=\"Anom_Avg\",\n",
    "                 hue = \"Up_Ds_Grp\", hue_order=grouporder,\n",
    "                 palette=\"winter_r\",\n",
    "                 linewidth=0.75,\n",
    "                 showfliers = False, # Comment this out to see outliers\n",
    "                 data =Avg_Anom_byDam, \n",
    "                 zorder = 3)\n",
    "ax.set_xlabel( \"Month\", fontsize=12) \n",
    "ax.set_ylabel( \"Average Temperature Anomaly (°C)\", fontsize=12) \n",
    "ax.set_ylim(-3,3)\n",
    "plt.locator_params(axis='y', nbins= 5)\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(1))\n",
    "\n",
    "# sns.move_legend(ax, title='', fontsize='8', loc =\"upper right\")\n",
    "ax.get_legend().remove()\n",
    "\n",
    "plt.savefig(r\"F:\\Insert_File_Path_Profile_Anomalies.png\", bbox_inches=\"tight\", pad_inches=0.25, dpi=1200) # Update this file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate if the anomlies are sigfnificantly different by months ### \n",
    "\n",
    "# List of Months\n",
    "Months = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "col_names =  ['Month', 'All_KW_Pval', 'Riv_KW_Pval', 'RR_KW_Pval', 'Res_KW_Pval']\n",
    "KW_Seas_Results  = pd.DataFrame(columns = col_names)\n",
    "\n",
    "for i in Months:\n",
    "    # Set up the subsets for comparison -- All\n",
    "    KruskalTest_1 = Avg_Anom_byDam[(Avg_Anom_byDam['Month'] == i) & (Avg_Anom_byDam['Up_Ds_Grp'] == \"Downstream River\")].Anom_Avg.tolist() # DS River\n",
    "    KruskalTest_2 = Avg_Anom_byDam[(Avg_Anom_byDam['Month'] == i) & (Avg_Anom_byDam['Up_Ds_Grp'] == \"Upstream River\")].Anom_Avg.tolist() # UP River\n",
    "    KruskalTest_3 = Avg_Anom_byDam[(Avg_Anom_byDam['Month'] == i) & (Avg_Anom_byDam['Up_Ds_Grp'] == \"Upstream Reservoir\")].Anom_Avg.tolist()  # UP Resrv\n",
    "    \n",
    "    # Run the test -- All \n",
    "    h_statistic, p_value = stats.kruskal(KruskalTest_1, KruskalTest_2, KruskalTest_3)\n",
    "\n",
    "    # Run the test -- Up River vs Ds River\n",
    "    h_statistic_riv, p_value_riv = stats.kruskal(KruskalTest_2,KruskalTest_1)\n",
    "\n",
    "    # Run the test -- River vs Resv (UP)\n",
    "    h_statistic_rr, p_value_rr = stats.kruskal(KruskalTest_2, KruskalTest_3)\n",
    "\n",
    "    # Run the test -- Up Resv vs Ds River\n",
    "    h_statistic_res, p_value_res = stats.kruskal(KruskalTest_3, KruskalTest_1)\n",
    "    \n",
    "\n",
    "    # Get Dictionary\n",
    "    dictionary = {'Month': i , 'All_KW_Pval': [p_value], 'Riv_KW_Pval': [p_value_riv], 'RR_KW_Pval': [p_value_rr], 'Res_KW_Pval': [p_value_res]}\n",
    "\n",
    "    df_dictionary = pd.DataFrame.from_dict(dictionary)\n",
    "    \n",
    "    # Add to DF\n",
    "    output = pd.concat([KW_Seas_Results, df_dictionary], ignore_index=True)\n",
    "    \n",
    "    KW_Seas_Results = output\n",
    "\n",
    "## Save and preview the significance by month\n",
    "KW_Seas_Results['All_KW_Pval_Sig'] = np.where((KW_Seas_Results['All_KW_Pval'] <= 0.05), 'Significant', 'Not Significant') # All Categories\n",
    "KW_Seas_Results['Riv_KW_Pval_Sig'] = np.where((KW_Seas_Results['Riv_KW_Pval'] <= 0.05), 'Significant', 'Not Significant') # Up River to DS River\n",
    "KW_Seas_Results['RR_KW_Pval_Sig'] = np.where((KW_Seas_Results['RR_KW_Pval'] <= 0.05), 'Significant', 'Not Significant') # Up River to Up Reserv\n",
    "KW_Seas_Results['Res_KW_Pval_Sig'] = np.where((KW_Seas_Results['Res_KW_Pval'] <= 0.05), 'Significant', 'Not Significant') # Up Reserv to DS River\n",
    "KW_Seas_Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Variance and STDV ##\n",
    "# Get Values for Each Month\n",
    "Avg_Anom_STDV_Prof = Avg_Anom_byDam.groupby([\"Month\", \"Up_Ds_Grp\"]).agg({'Anom_Avg':['std','var']})\n",
    "Avg_Anom_STDV_Prof.columns = ['Anom_STDV', 'Anom_Var']\n",
    "Avg_Anom_STDV_Prof = Avg_Anom_STDV_Prof.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "########## Get Downstream Differences by Distance ###############\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get a Copy of All Temps for the Relevant Profiles\n",
    "Profile_Temp_Points = pd.merge(HydroDams_Clean, UpAnDown, on=['Assgn_dam','Month','Day', 'Year'], how = 'inner')\n",
    "Profile_Temp_Points = Profile_Temp_Points[['Join_Node', 'Assgn_dam', 'Month', 'Day', 'Year', 'Avg_Temp', 'Avg_RWC_Wid', 'x', 'y', 'reach_id', \n",
    "                                          'lakeflag', 'Dam_Flag', 'Up_Ds', 'Up_Ds_Grp', 'Dam_Dist', 'Dam_Dist_km', 'HydroCode']] # clean up columns\n",
    "\n",
    "# List of Profiles with Up and DS Averages\n",
    "# Get Up Avg \n",
    "Upstream_Points = Profile_Temp_Points[(Profile_Temp_Points['Up_Ds_Grp'] == \"Upstream River\")]\n",
    "Upstream_Avg = Upstream_Points.groupby(['Month','Day','Year','Assgn_dam']).agg({'Avg_Temp': ['mean']})\n",
    "Upstream_Avg.columns = ['Up_Avg']\n",
    "Upstream_Avg = Upstream_Avg.reset_index()\n",
    "\n",
    "# Get DS 20km Avg\n",
    "Downstream_Riv = Profile_Temp_Points[(Profile_Temp_Points['Up_Ds_Grp'] == 'Downstream River') & (Profile_Temp_Points['Dam_Dist_km'] <= 20) ]\n",
    "Downstream_Avgs_Riv = Downstream_Riv.groupby(['Month','Day','Year','Assgn_dam']).agg({'Avg_Temp': ['mean']})\n",
    "Downstream_Avgs_Riv.columns = ['Ds_Avg_20']\n",
    "Downstream_Avgs_Riv = Downstream_Avgs_Riv.reset_index()\n",
    "\n",
    "Profile_Avgs_UPDS_Riv = pd.merge(Upstream_Avgs_Riv, Downstream_Avgs_Riv, on=['Month','Day', 'Year','Assgn_dam'], how='outer' )\n",
    "\n",
    "Profile_Avgs_UPDS_Riv['Temp_Diff_20'] = Profile_Avgs_UPDS_Riv['Ds_Avg_20'] - Profile_Avgs_UPDS_Riv['Up_Avg'] \n",
    "Profile_Avgs_UPDS_Riv['Abs_Temp_Diff_20'] = abs(Profile_Avgs_UPDS_Riv['Ds_Avg_20'] - Profile_Avgs_UPDS_Riv['Up_Avg'])\n",
    "Profile_Avgs_UPDS_Riv['Temp_Direction'] = np.where(Profile_Avgs_UPDS_Riv['Temp_Diff_20']>0, \"Warmer\", \"Cooler\")\n",
    "\n",
    "## Combine Averages back to Points ## \n",
    "Profile_Absolute_Diff = pd.merge(Profile_Temp_Points,Profile_Avgs_UPDS_Riv, on=['Assgn_dam','Month','Day', 'Year'], how='left' )\n",
    "\n",
    "## Get Absolute Differences ##\n",
    "Profile_Absolute_Diff['Diff_UP_Node'] = Profile_Absolute_Diff['Avg_Temp'] - Profile_Absolute_Diff['Up_Avg']\n",
    "Profile_Absolute_Diff['Abs_Diff_UP_Node'] = abs(Profile_Absolute_Diff['Avg_Temp'] - Profile_Absolute_Diff['Up_Avg'])\n",
    "\n",
    "# Get the Signif Attached \n",
    "Signif_Flag = KW_Prof_Results_Riv20[['Assgn_dam','Month','Day', 'Year', 'KW_Sig_05']]\n",
    "\n",
    "Profile_Differences = pd.merge(Profile_Absolute_Diff,Signif_Flag, on=['Assgn_dam','Month','Day', 'Year'], how='left' )\n",
    "\n",
    "## Save the File ## \n",
    "Profile_Differences.to_csv(r\"F:\\Insert_File_Path_Profile_Points_Diffs.csv\") # Update this file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Prepare to plot it ##### -- Figure 3D\n",
    "Plot_Diff = Profile_Differences[:]\n",
    "\n",
    "# Filter to less than 60 km downstream\n",
    "Plot_Diff = Plot_Diff[Plot_Diff[\"Dam_Dist_km\"] <= 60]\n",
    "\n",
    "# Filter to just river nodes \n",
    "Plot_Diff = Plot_Diff[Plot_Diff[\"Up_Ds_Grp\"] == \"Downstream River\"]\n",
    "\n",
    "# Group by season, distance, and increasing or decreasing\n",
    "Plot_Diff['Dam_Dist_km_c'] = Plot_Diff['Dam_Dist_km'].apply(math.ceil)\n",
    "\n",
    "# Assign seasons according to the months\n",
    "Plot_Diff[\"Season\"] = np.nan\n",
    "Plot_Diff[\"Season\"] = np.where(Plot_Diff[\"Month\"].isin([12, 1, 2]), \"Winter\", Plot_Diff[\"Season\"])\n",
    "Plot_Diff[\"Season\"] = np.where(Plot_Diff[\"Month\"].isin([3, 4, 5]), \"Spring\", Plot_Diff[\"Season\"])\n",
    "Plot_Diff[\"Season\"] = np.where(Plot_Diff[\"Month\"].isin([6,7,8]), \"Summer\", Plot_Diff[\"Season\"])\n",
    "Plot_Diff[\"Season\"] = np.where(Plot_Diff[\"Month\"].isin([9, 10, 11]), \"Fall\", Plot_Diff[\"Season\"])\n",
    "\n",
    "### Use only SIgnificant Differences ###\n",
    "Plot_Diff_Signif =Plot_Diff[(Plot_Diff[\"KW_Sig_05\"] == \"Significant\") & (Plot_Diff[\"Dam_Dist_km_c\"] <= 20)]\n",
    "\n",
    "# Group by season, distance, and increasing or decreasing\n",
    "Plot_Diff_Signif['Dam_Dist_km_c'] = Plot_Diff_Signif['Dam_Dist_km'].apply(math.ceil)\n",
    "Plot_Diff_Signif_Season = Plot_Diff_Signif.groupby([\"Season\", \"Dam_Dist_km_c\", \"Temp_Direction\"]).agg({'Diff_UP_Node':['mean']})\n",
    "Plot_Diff_Signif_Season.columns=[\"Diff_UP_Node\"]\n",
    "Plot_Diff_Signif_Season = Plot_Diff_Signif_Season.reset_index()\n",
    "\n",
    "Plot_Diff_Signif_Annual = Plot_Diff_Signif.groupby([\"Dam_Dist_km_c\", \"Temp_Direction\"]).agg({'Diff_UP_Node':['mean']})\n",
    "Plot_Diff_Signif_Annual.columns=[\"Diff_UP_Node\"]\n",
    "Plot_Diff_Signif_Annual = Plot_Diff_Signif_Annual.reset_index()\n",
    "\n",
    "##### Plot the Avg DS difference (1km) for first 20km of profiles with significant differences ###\n",
    "\n",
    "pal = [\"#031730\",  \"#F94994\", \"#006A5C\",\"#EB9911\"]\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(10,4))\n",
    "\n",
    "ax =  sns.lineplot(x=\"Dam_Dist_km_c\", y=\"Diff_UP_Node\", data=Plot_Diff_Signif_Season[Plot_Diff_Signif_Season[\"Temp_Direction\"] == \"Warmer\"],\n",
    "            hue=\"Season\", palette=sns.color_palette(pal), hue_order=[\"Winter\", \"Spring\", \"Summer\", \"Fall\"], zorder=2)\n",
    "\n",
    "sns.lineplot(x=\"Dam_Dist_km_c\", y=\"Diff_UP_Node\", data=Plot_Diff_Signif_Season[Plot_Diff_Signif_Season[\"Temp_Direction\"] == \"Cooler\"],\n",
    "            hue=\"Season\", palette=sns.color_palette(pal), hue_order=[\"Winter\", \"Spring\", \"Summer\", \"Fall\"], zorder=2, legend=False)\n",
    "\n",
    "sns.lineplot(x=\"Dam_Dist_km_c\", y=\"Diff_UP_Node\", data=Plot_Diff_Signif_Annual[Plot_Diff_Signif_Annual[\"Temp_Direction\"] == \"Warmer\"], color='#6F4E37', label=\"Annual\", linestyle='dashed',  linewidth=2, zorder=2)\n",
    "sns.lineplot(x=\"Dam_Dist_km_c\", y=\"Diff_UP_Node\", data=Plot_Diff_Signif_Annual[Plot_Diff_Signif_Annual[\"Temp_Direction\"] == \"Cooler\"], color='#6F4E37',  linestyle='dashed',  linewidth=2, zorder=2, legend=False)\n",
    "\n",
    "ax.set_xlim(1, 20)\n",
    "ax.set_ylim(-2, 2)\n",
    "ax.set_xticks([2,4,6,8,10,12,14,16,18,20])\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.25))\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.axhline(0, linewidth = 0.8, color='black')\n",
    "\n",
    "r = [-1.5, -1, -0.5, 0, 0.5, 1, 1.5]\n",
    "for i in r:\n",
    "    ax.axhline(i, linewidth=0.8, color='lightgrey', zorder=0)\n",
    "\n",
    "for i in range(1, 21, 1):\n",
    "    ax.axvline(i, linewidth=0.8, color='lightgrey', zorder=0)\n",
    "\n",
    "ax.set_xlabel(\"Downstream Distance from dam (km)\",  fontsize=14)\n",
    "ax.set_ylabel(\"Temperature Difference ($^\\circ$C)\",  fontsize=14)\n",
    "ax.legend(title=None, ncol=3, fontsize=12)\n",
    "\n",
    "ax.spines['top'].set_color('black')\n",
    "ax.spines['right'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "ax.spines['left'].set_color('black')\n",
    "\n",
    "plt.savefig(r\"F:\\Insert_File_Path_Avg_DS_Dist_20km.png\", bbox_inches=\"tight\", pad_inches=0.25, dpi=1200) # Update this file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look for Significant trends with DS Distance\n",
    "Slope_P_Col = ['Season', 'Direction', 'Slope', 'Pval']\n",
    "DS_Dist_Slope_P = pd.DataFrame(columns = Slope_P_Col)\n",
    "\n",
    "# Get Unique Groupings\n",
    "Groups = Plot_Diff_Signif_Season.groupby(['Season','Temp_Direction']).agg({'Dam_Dist_km_c': ['count']})\n",
    "Groups.columns = ['Count']\n",
    "Groups = Groups.reset_index()\n",
    "\n",
    "for i in range(len(Groups)):\n",
    "    Group_Filter = Plot_Diff_Signif_Season[(Plot_Diff_Signif_Season['Season'] == Groups.iloc[i,0]) & (Plot_Diff_Signif_Season['Temp_Direction'] == Groups.iloc[i,1])]\n",
    "\n",
    "    Dist = Group_Filter['Dam_Dist_km_c'].tolist()\n",
    "    Temp = Group_Filter['Diff_UP_Node'].tolist()\n",
    "\n",
    "    # Get the regression\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(Dist, Temp)\n",
    "\n",
    "    # Get Dictionary\n",
    "    dictionary = {'Season': Groups.iloc[i, 0], 'Direction': Groups.iloc[i,1], 'Slope': [slope], 'Pval': [p_value]}\n",
    "    \n",
    "    df_dictionary = pd.DataFrame.from_dict(dictionary)\n",
    "    \n",
    "    # Add to DF\n",
    "    output = pd.concat([DS_Dist_Slope_P, df_dictionary], ignore_index=True)\n",
    "    \n",
    "    DS_Dist_Slope_P = output\n",
    "\n",
    "DS_Dist_Slope_P[\"Signif\"] = np.where((DS_Dist_Slope_P['Pval'] <= 0.05), 'Significant', 'Not Significant')\n",
    "DS_Dist_Slope_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check Significance of Annual Warm\n",
    "Warm = Plot_Diff_Signif_Season[(Plot_Diff_Signif_Season['Temp_Direction'] == 'Warmer')]\n",
    "\n",
    "Dist_w = Warm['Dam_Dist_km_c'].tolist()\n",
    "Temp_w = Warm['Diff_UP_Node'].tolist()\n",
    "\n",
    "# Get the regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(Dist_w, Temp_w)\n",
    "\n",
    "print (\"Slope: \" + str(slope) + \", P Value: \" + str(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check Significance of Annual Cool\n",
    "Cool = Plot_Diff_Signif_Season[(Plot_Diff_Signif_Season['Temp_Direction'] == 'Cooler')]\n",
    "\n",
    "Dist_c = Cool['Dam_Dist_km_c'].tolist()\n",
    "Temp_c = Cool['Diff_UP_Node'].tolist()\n",
    "\n",
    "# Get the regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(Dist_c, Temp_c)\n",
    "\n",
    "print (\"Slope: \" + str(slope) + \", P Value: \" + str(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Plot The Downstream  Anomalies -- Figure 4C ########\n",
    "# Subset the data\n",
    "Riv_Diff_Anom = Profile_Differences[Profile_Differences['Dam_Dist_km'] <= 60]\n",
    "\n",
    "# Get the Average Anomalies\n",
    "Avg_Anom_byUPRiv = Riv_Diff_Anom.groupby([\"Up_Ds_Grp\", \"Month\",\"Day\",\"Year\",\"Assgn_dam\"]).agg({'Diff_UP_Node':['mean','count']})\n",
    "Avg_Anom_byUPRiv.columns = ['Anom_Avg', 'NPoints']\n",
    "Avg_Anom_byUPRiv = Avg_Anom_byUPRiv.reset_index()\n",
    "Avg_Anom_byUPRiv\n",
    "\n",
    "\n",
    "# Set the order of groups for boxplots\n",
    "grouporder = ['Upstream River', 'Upstream Reservoir', 'Downstream River']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6,4))\n",
    "ax = sns.boxplot(x=\"Month\", y=\"Anom_Avg\",\n",
    "                 hue = \"Up_Ds_Grp\", hue_order=grouporder,\n",
    "                 palette=\"winter_r\",\n",
    "                 linewidth=0.75,\n",
    "                 showfliers = False, # Comment this out to see outliers\n",
    "                 data =Avg_Anom_byUPRiv, \n",
    "                 zorder = 3)\n",
    "ax.set_xlabel( \"Month\", fontsize=12)\n",
    "ax.set_ylabel( \"Average Temperature Anomaly (°C)\", fontsize=12) \n",
    "ax.tick_params(labelsize=12)\n",
    "ax.set_ylim(-7,7)\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(1))\n",
    "ax.get_legend().remove()\n",
    "\n",
    "plt.savefig(r\"F:\\Insert_File_Path_to_Anomalies_to_UPRiver.png\", bbox_inches=\"tight\", pad_inches=0.25, dpi=1200) # Update this file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "####### Create some base info for graphics #######\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a study area map ### -- Figure 1A\n",
    "# Get List of Dams Used\n",
    "Dams_of_Interest = Profile_Differences[\"Assgn_dam\"].unique().tolist()\n",
    "Dams_of_Interest.sort()\n",
    "\n",
    "# Fliter the List \n",
    "BestDams = Dams[Dams[\"grod_id\"].isin(Dams_of_Interest)]\n",
    "\n",
    "## Set up Map ##\n",
    "# State Boundaries\n",
    "USA = gpd.read_file(r\"F:\\Insert_Path_to_USA_State_Outlines.shp\") ## Shapefile of the USA to be filtered and mapped # Update this file path\n",
    "USA=USA.to_crs(4326)\n",
    "\n",
    "# Filter USA file to CONUS if needed\n",
    "CONUS = USA[(~USA['NAME'].isin([ 'Alaska','American Samoa', 'District of Columbia', 'Fed States of Micronesia', 'Guam', 'Hawaii','Marshall Islands', 'Northern Mariana Islands','Palau', 'Puerto Rico', 'Virgin Islands', 'District of Columbia']))]\n",
    "\n",
    "## Large Rivers\n",
    "SWORD = gpd.read_file(r\"F:\\Insert_Path_to_NA_SWORD_reach_v16_gt100_map.shp\") ## Combined SWORD centerlines > 100m, completed in ArcGIS # Update this file path\n",
    "SWORD = SWORD.to_crs(4326)\n",
    "\n",
    "## 87 Gages used in AA\n",
    "GageSites_gdf =  gpd.read_file(r\"F:\\Insert_Path_to_USGS_Gages_AA_n87.shp\")  # Update this file path\n",
    "GageSites_gdf = GageSites_gdf.to_crs(4326)\n",
    "\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "bufferforplot = SWORD.buffer(0.1) ## Buffered for visualization purposes only \n",
    "\n",
    "# Plot Data\n",
    "fig, ax=plt.subplots(figsize=(14,10))\n",
    "CONUS.plot(ax=ax,color='whitesmoke', edgecolor='dimgray', linewidth = 0.7, alpha = 0.75, zorder = 1)\n",
    "bufferforplot.plot(ax=ax,color='#006c7a',  linewidth = 0.01, alpha = 0.9,  label = \"Rivers (>100m)\", zorder = 2)\n",
    "BestDams.plot(ax=ax, marker='^', markersize = 50, color = \"#fb5607\", edgecolor = \"#F98D5A\",  linewidth = 0.5, label = \"Dams\", zorder=4)\n",
    "GageSites_gdf.plot( ax = ax, marker = \"o\", markersize = 50, color = '#5603ad', edgecolor = \"#8367c7\", linewidth = 0.5,  label = \"USGS Gages\", zorder=3)\n",
    "fig.legend(loc = \"outside upper right\")\n",
    "\n",
    "fig.savefig(r\"F:\\Insert_Path_to_Study_Area_Map.png\", bbox_inches=\"tight\", pad_inches=0.25, dpi=1200) # Update this file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## GET PROFILE INFO ##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Number of Profiles by Season Graphic -- Figure 3A \n",
    "# Get the total number of profiles per month\n",
    "NumberofProfiles = KW_Prof_Results_Riv20.groupby(\"Month\").agg({'Month': ['count']})\n",
    "NumberofProfiles.columns = [\"Month_Count\"]\n",
    "NumberofProfiles = NumberofProfiles.reset_index()\n",
    "\n",
    "# Assign the seasons\n",
    "NumberofProfiles[\"Season\"] = np.nan\n",
    "NumberofProfiles[\"Season\"] = np.where(NumberofProfiles['Month'].isin([12, 1, 2]), 'Winter', NumberofProfiles['Season'])\n",
    "NumberofProfiles[\"Season\"] = np.where(NumberofProfiles['Month'].isin([3, 4, 5]), 'Spring', NumberofProfiles['Season'])\n",
    "NumberofProfiles[\"Season\"] = np.where(NumberofProfiles['Month'].isin([6, 7, 8]), 'Summer', NumberofProfiles['Season'])\n",
    "NumberofProfiles[\"Season\"] = np.where(NumberofProfiles['Month'].isin([9, 10, 11]), 'Fall', NumberofProfiles['Season'])\n",
    "\n",
    "## Plot the profile counts \n",
    "ColorPalette = ['#031730','#F94994', '#006A5C', '#EB9911']\n",
    "HueOrder = [\"Winter\",\"Spring\",\"Summer\",\"Fall\"]\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(6,4))\n",
    "ax = sns.barplot(NumberofProfiles, x=\"Month\", y=\"Month_Count\", hue =\"Season\", hue_order = HueOrder, palette = ColorPalette)\n",
    "ax.set_xlabel( \"Month\", fontsize=14) \n",
    "ax.set_ylabel( \"Number of Profiles\", fontsize=14) \n",
    "ax.set_title(\"Total Number of Profiles by Month 2013-2024\", fontsize = 14)\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.legend(title=None, ncol=2, fontsize=12)\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(100))\n",
    "\n",
    "fig.savefig(r\"F:\\Insert_Path_to_Profile_Number_Season.png\", bbox_inches=\"tight\", pad_inches=0.25, dpi=1200) # Update this file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Profile Average Temperatures -- Figure 3B\n",
    "EntireProf = pd.read_csv(r\"Insert_File_Path_for_All_Entire_Profile_Averages.csv\") # Created for FIg 4B ## Update this file path\n",
    "Prof_Avg = pd.merge(KW_Prof_Results_Riv20, EntireProf, on=['Month', 'Day','Year','Assgn_dam'], how='inner')\n",
    "\n",
    "# Assign the season \n",
    "Prof_Avg[\"Season\"] = np.nan\n",
    "Prof_Avg[\"Season\"] = np.where(Prof_Avg['Month'].isin([12, 1, 2]), 'Winter', Prof_Avg['Season'])\n",
    "Prof_Avg[\"Season\"] = np.where(Prof_Avg['Month'].isin([3, 4, 5]), 'Spring', Prof_Avg['Season'])\n",
    "Prof_Avg[\"Season\"] = np.where(Prof_Avg['Month'].isin([6, 7, 8]), 'Summer', Prof_Avg['Season'])\n",
    "Prof_Avg[\"Season\"] = np.where(Prof_Avg['Month'].isin([9, 10, 11]), 'Fall', Prof_Avg['Season'])\n",
    "\n",
    "# Plot the Profile Average Temperatures\n",
    "ColorPalette = ['#031730','#F94994', '#006A5C', '#EB9911']\n",
    "HueOrder = [\"Winter\",\"Spring\",\"Summer\",\"Fall\"]\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(6,4))\n",
    "ax = sns.boxenplot(data=Prof_Avg, y=\"Prof_Avg\", hue = \"Season\", hue_order = HueOrder, palette = ColorPalette, width = 0.75)\n",
    "ax.set_ylabel( \"Profile Average Temperature (°C)\", fontsize=14) \n",
    "ax.set_title(\"Average Profile Temperature Distribution\", fontsize = 14)\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(5))\n",
    "ax.legend(title=None, fontsize=12)\n",
    "\n",
    "fig.savefig(r\"F:\\Insert_File_Path_for_Profile_AvgTemps_Season.png\", bbox_inches=\"tight\", pad_inches=0.25, dpi=1200) # Update this file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "## Investigate the Downstream Differences by Dam Type ##\n",
    "################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the temperature differences by dam type (with a reservoir or without a reservoir ) and direction of change --- Figure 3C ###\n",
    "# Prep the data\n",
    "Dam_Info = Dams[['grod_id','type','dataset']]\n",
    "Dam_Info['dataset'].unique()\n",
    "\n",
    "# Make an easier code for hydropower variables -- Simplified options for analysis\n",
    "Dam_Info['Resv']  = np.nan\n",
    "Dam_Info['Resv'] = np.where((Dam_Info['dataset'] == 'Hydropower dam associated with reservoir and power plant') , 'Reservoir', Dam_Info['Resv'])\n",
    "Dam_Info['Resv'] = np.where((Dam_Info['dataset'] == 'Hydropower dam associated with reservoir; no power plant') , 'Reservoir', Dam_Info['Resv'])\n",
    "Dam_Info['Resv'] = np.where((Dam_Info['dataset'] == 'Hydropower dam associated with power plant; no reservoir') , 'No Reservoir', Dam_Info['Resv'])\n",
    "Dam_Info['Resv'] = np.where((Dam_Info['dataset'] == 'Hydropower dam only; no reservoir or power plant') , 'No Reservoir', Dam_Info['Resv'])\n",
    "\n",
    "## Assessed the dams w/o Hydropower manually for reservoirs (e.g., imagery, NID, SWORD node classification) ##\n",
    "# Pull in the list of dams and classifications \n",
    "NonHydroTypes = pd.read_csv(r\"F:\\Insert_Path_for_Dam_Reservoir_Check.csv\") # Update this file path\n",
    "\n",
    "## Join the Data & Get the Dam Counts ##\n",
    "DamTypeRes = pd.merge(Dam_Info, NonHydroTypes, on=\"grod_id\", how=\"left\")\n",
    "DamTypeRes[\"Resv\"] = np.where((DamTypeRes['Manual_Check'] == 'NoReserv') , 'No Reservoir', DamTypeRes['Resv'])\n",
    "DamTypeRes[\"Resv\"] = np.where((DamTypeRes['Manual_Check'] == 'Reserv') , 'Reservoir', DamTypeRes['Resv'])\n",
    "\n",
    "# Join to get the Dam Totals\n",
    "Dam_Totals = pd.merge(KW_Prof_Results_Riv20[['Assgn_dam','Month','Day','Year','KW_Sig_05']], DamTypeRes, left_on = 'Assgn_dam', right_on = 'grod_id' , how='left').drop(columns = [ 'grod_id'])\n",
    "\n",
    "# Get the differences\n",
    "Diff_Sign = Profile_Avgs_Riv[:]\n",
    "Diff_Sign[\"Diff_Direction\"] = np.nan\n",
    "Diff_Sign[\"Diff_Direction\"] = np.where((Diff_Sign[\"Temp_Diff\"] < 0) , 'Cooler', Diff_Sign[\"Diff_Direction\"])\n",
    "Diff_Sign[\"Diff_Direction\"] = np.where((Diff_Sign[\"Temp_Diff\"] > 0) , 'Warmer', Diff_Sign[\"Diff_Direction\"])\n",
    "\n",
    "# Join Temp Directions with the Dam Info\n",
    "Dam_Totals_Diff = pd.merge(Dam_Totals, Diff_Sign[['Month', 'Day','Year','Assgn_dam','Temp_Diff', 'Diff_Direction']], on=['Month', 'Day','Year','Assgn_dam'], how='left')\n",
    "Dam_Totals_Diff[\"Diff_Direction\"]= np.where((Dam_Totals_Diff[\"Diff_Direction\"].isna()) , 'No Change', Dam_Totals_Diff[\"Diff_Direction\"]) # can't have nulls in a later step\n",
    "\n",
    "# Get the Profile Counts by Dam \n",
    "DamType_Info_ResSplit = Dam_Totals_Diff.groupby([\"Assgn_dam\",\"type\",\"Resv\",\"KW_Sig_05\",\"Diff_Direction\"]).agg({'Month': ['count']})\n",
    "DamType_Info_ResSplit.columns = [\"Profile Count\"]\n",
    "DamType_Info_ResSplit = DamType_Info_ResSplit.reset_index()\n",
    "\n",
    "# Get Dam Type Profile Stats -- Supplemental Table 1\n",
    "# Get the Data Range\n",
    "def calculate_range(x):\n",
    "    return x.max() - x.min()\n",
    "\n",
    "ResNoRes_Details  = Dam_Totals_Diff[:]\n",
    "ResNoRes_Details['Temp_Diff'] = np.where(ResNoRes_Details['Temp_Diff'].isna(), 0, ResNoRes_Details['Temp_Diff'])\n",
    "ResProfCount_Type_Dir = ResNoRes_Details.groupby([\"Resv\",\"Diff_Direction\"]).agg({'Month': ['count'], 'Temp_Diff': ['mean', 'std', calculate_range]})\n",
    "ResProfCount_Type_Dir.columns = ['Profile_Count','Avg_Diff', 'STDV', 'Range']\n",
    "ResProfCount_Type_Dir = ResProfCount_Type_Dir.reset_index()\n",
    "\n",
    "## Save the Data \n",
    "ResProfCount_Type_Dir.to_csv(r\"F:\\Insert_Path_for_Diffeerence_Stats_by_Dam_Type.csv\")  # Update this file path\n",
    "\n",
    "## Look at just the changes \n",
    "ResNoRes = ResProfCount_Type_Dir[ResProfCount_Type_Dir['Diff_Direction']!= 'No Change']\n",
    "\n",
    "# Preview the Data -- Table S2\n",
    "ResNoRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Format the Data for Rose Plot, Plot, &  Save ###\n",
    "Profile_PolarPlot = ResProfCount_Type_Dir[:]\n",
    "\n",
    "# Name the groups \n",
    "Profile_PolarPlot[\"GroupName\"] = np.nan\n",
    "# Reservoir\n",
    "Profile_PolarPlot[\"GroupName\"] = np.where(((Profile_PolarPlot['Diff_Direction'] == 'Cooler') & (Profile_PolarPlot[\"Resv\"] == \"Reservoir\")), 'Reservoir-Cooler', Profile_PolarPlot['GroupName'])\n",
    "Profile_PolarPlot[\"GroupName\"] = np.where(((Profile_PolarPlot['Diff_Direction'] == 'Warmer') & (Profile_PolarPlot[\"Resv\"] == \"Reservoir\")), 'Reservoir-Warmer', Profile_PolarPlot['GroupName'])\n",
    "Profile_PolarPlot[\"GroupName\"] = np.where(((Profile_PolarPlot['Diff_Direction'] == 'No Change') & (Profile_PolarPlot[\"Resv\"] == \"Reservoir\")), 'Reservoir-NC', Profile_PolarPlot['GroupName'])\n",
    "# No Reservoir\n",
    "Profile_PolarPlot[\"GroupName\"] = np.where(((Profile_PolarPlot['Diff_Direction'] == 'Cooler') & (Profile_PolarPlot[\"Resv\"] == \"No Reservoir\")), 'No Reservoir-Cooler', Profile_PolarPlot['GroupName'])\n",
    "Profile_PolarPlot[\"GroupName\"] = np.where(((Profile_PolarPlot['Diff_Direction'] == 'Warmer') & (Profile_PolarPlot[\"Resv\"] == \"No Reservoir\")), 'No Reservoir-Warmer', Profile_PolarPlot['GroupName'])\n",
    "Profile_PolarPlot[\"GroupName\"] = np.where(((Profile_PolarPlot['Diff_Direction'] == 'No Change') & (Profile_PolarPlot[\"Resv\"] == \"No Reservoir\")), 'No Reservoir-NC', Profile_PolarPlot['GroupName'])\n",
    "\n",
    "import plotly.express as px\n",
    "fig = px.bar_polar(Profile_PolarPlot, r=\"Profile_Count\", theta=\"GroupName\", color=\"Avg_Diff\", color_continuous_scale = [\"#1c7379\", \"#eeddd4\", \"#c64436\"],).update_layout(polar_hole=0.1, height=600, width=800, margin=dict(b=30, t=30, l=0, r=0))\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(r'F:\\Insert_Path_for_ProfileStats_ReservType.pdf')  # Update this file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the spread of the differences by dam type and direction ### --- Figure S2\n",
    "\n",
    "# Get the siginifcant profiles \n",
    "SignifProf_DamType = ResNoRes_Details[ResNoRes_Details['Diff_Direction']!= 'No Change' ]\n",
    "\n",
    "# Set the plot details \n",
    "ColorPalette = [\"#1c7379\", \"#c64436\"]\n",
    "HueOrder = [\"Cooler\",\"Warmer\"]\n",
    "\n",
    "# Plot\n",
    "fig, ax=plt.subplots(figsize=(3,5))\n",
    "ax = sns.boxenplot(data=SignifProf_DamType, x='Resv', y='Temp_Diff', hue = \"Diff_Direction\", hue_order = HueOrder, palette = ColorPalette, linecolor= \"#1F201F\", width = 0.75, flier_kws=dict(facecolor=\"#1F201F\", linewidth=.25))\n",
    "ax.set_xlabel( \"\") \n",
    "ax.set_ylabel( \"Downstream Temperature Difference (°C)\", fontsize=12) \n",
    "ax.tick_params(labelsize=10)\n",
    "ax.legend(title=None, loc = 'lower right' ,fontsize=10)\n",
    "ax.set_ylim(-15,10)\n",
    "\n",
    "# Save Figure\n",
    "fig.savefig(r\"F:\\Insert_Path_for_Signif_DS_TempDiffs.pdf\", bbox_inches=\"tight\", pad_inches=0.25, dpi=300) # Update this file path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show Example Longitudinal Profiles (Cooler, Warmer, No Change) ### --- Figure 1C\n",
    "\n",
    "## Plots will need the UP and DS averages for each profile  ##\n",
    "# Get the Profiles and Nodes -- Copy\n",
    "Signif_Prof_Points = Signif_Riv20_Profile_Nodes[Signif_Riv20_Profile_Nodes[\"KW_Sig_05\"] == \"Significant\"]\n",
    "\n",
    "# Of The Significant Profiles -- Avg Diff Up Vs Ds \n",
    "Signif_Prof_Points_UP = Signif_Prof_Points[(Signif_Prof_Points['Up_Ds_Grp'] == \"Upstream River\")]\n",
    "Signif_Prof_Points_UP_avg = Signif_Prof_Points_UP.groupby(['Month','Day','Year','Assgn_dam']).agg({'Avg_Temp': ['mean']})\n",
    "Signif_Prof_Points_UP_avg.columns = ['Up_Avg']\n",
    "Signif_Prof_Points_UP_avg = Signif_Prof_Points_UP_avg.reset_index()\n",
    "\n",
    "Signif_Prof_Points_DS = Signif_Prof_Points[(Signif_Prof_Points['Up_Ds_Grp'] == 'Downstream River')]\n",
    "Signif_Prof_Points_DS_avg = Signif_Prof_Points_DS.groupby(['Month','Day','Year','Assgn_dam']).agg({'Avg_Temp': ['mean']})\n",
    "Signif_Prof_Points_DS_avg.columns = ['Ds_Avg']\n",
    "Signif_Prof_Points_DS_avg = Signif_Prof_Points_DS_avg.reset_index()\n",
    "\n",
    "UpDS_Avg = pd.merge(Signif_Prof_Points_UP_avg, Signif_Prof_Points_DS_avg, on=['Month','Day', 'Year','Assgn_dam'], how='outer' )\n",
    "\n",
    "UpDS_Avg['Temp_Diff'] = UpDS_Avg['Ds_Avg'] - UpDS_Avg['Up_Avg'] \n",
    "\n",
    "## Colder Example  ## \n",
    "# Set up the plot \n",
    "fig, ax=plt.subplots(figsize=(8,6))\n",
    "\n",
    "# Get the profile for Dam 306 on Sept. 8, 2021\n",
    "ProfTest = Signif_Prof_Points[(Signif_Prof_Points['Month'] == 9) & (Signif_Prof_Points['Day'] == 8) & (Signif_Prof_Points['Year'] == 2021) & (Signif_Prof_Points['Assgn_dam'] == 306)]\n",
    "ProfTest_Avg_up = Profile_Avgs_Riv[(Profile_Avgs_Riv['Month'] == 9) & (Profile_Avgs_Riv['Day'] == 8) & (Profile_Avgs_Riv['Year'] == 2021)& (Profile_Avgs_Riv['Assgn_dam'] == 306)].Up_Avg\n",
    "ProfTest_Avg_ds = Profile_Avgs_Riv[(Profile_Avgs_Riv['Month'] == 9) & (Profile_Avgs_Riv['Day'] == 8) & (Profile_Avgs_Riv['Year'] == 2021) &(Profile_Avgs_Riv['Assgn_dam'] == 306)].Ds_Avg\n",
    "\n",
    "# Plot \n",
    "sns.lineplot(data = ProfTest[(ProfTest['Up_Ds_Grp'] ==\"Upstream River\")], x = 'Dam_Dist_km', y ='Avg_Temp', color = \"#18A790\", linewidth=2, label = \"Upstream River\")\n",
    "sns.lineplot(data = ProfTest[(ProfTest['Up_Ds_Grp'] ==\"Upstream Reservoir\")], x = 'Dam_Dist_km', y ='Avg_Temp', color = \"#1877A8\", linewidth=2, label = \"Reservoir\")\n",
    "sns.lineplot(data = ProfTest[(ProfTest['Up_Ds_Grp'] ==\"Downstream River\")], x = 'Dam_Dist_km', y ='Avg_Temp', color = \"#1C4BC4\", label = \"Downstream River\")\n",
    "plt.hlines(y=ProfTest_Avg_up, xmin=(ProfTest[ProfTest['Up_Ds_Grp'] ==\"Upstream River\"].Dam_Dist_km.min()), xmax= (ProfTest[ProfTest['Up_Ds_Grp'] ==\"Upstream River\"].Dam_Dist_km.max()) , linewidth=2, color='#7F0824', alpha = 0.8)\n",
    "plt.hlines(y=ProfTest_Avg_ds, xmin= (ProfTest[ProfTest[\"Up_Ds\"]==\"Downstream\"].Dam_Dist_km.min()), xmax= (ProfTest[ProfTest[\"Up_Ds\"]==\"Downstream\"].Dam_Dist_km.max()), linewidth=3, color='#7F0824',alpha = 0.8, label = \"Average Temperature\")\n",
    "plt.axvline(x=0.15, linewidth=3, color='#fb5607', linestyle='--', zorder = 1, label = 'Dam')\n",
    "plt.xlabel(\"Distance Downstream (km)\", fontsize = 16)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.xlim(-45,21)\n",
    "plt.ylabel(\"Water Surface Temperature (°C)\", fontsize = 16)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(loc='lower left', prop={'size': 16})\n",
    "plt.locator_params(axis='y', nbins= 6)\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(r\"F:\\Insert_Path_for_Colder_Profile_09082021.png\", bbox_inches=\"tight\", pad_inches=0.25, dpi=1200) # Update this file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Warmer Example ## \n",
    "# Set up plot\n",
    "fig, ax=plt.subplots(figsize=(8,6))\n",
    "\n",
    "# Get profile for Dam 306 on Feb. 15, 2021\n",
    "ProfTest = Signif_Prof_Points[(Signif_Prof_Points['Month'] == 2) & (Signif_Prof_Points['Day'] == 15) &(Signif_Prof_Points['Assgn_dam'] == 306) ]\n",
    "ProfTest_Avg_up = Profile_Avgs_Riv[(Profile_Avgs_Riv['Month'] == 2) & (Profile_Avgs_Riv['Day'] == 15) &(Profile_Avgs_Riv['Assgn_dam'] == 306)].Up_Avg\n",
    "ProfTest_Avg_ds = Profile_Avgs_Riv[(Profile_Avgs_Riv['Month'] == 2) & (Profile_Avgs_Riv['Day'] == 15) &(Profile_Avgs_Riv['Assgn_dam'] == 306)].Ds_Avg\n",
    "\n",
    "# Single spurious point, removed for visualization\n",
    "MisclassPoint = ProfTest[(ProfTest['Up_Ds_Grp'] ==\"Upstream Reservoir\")].Dam_Dist_km.min()\n",
    "\n",
    "# Plot\n",
    "sns.lineplot(data = ProfTest[(ProfTest['Up_Ds_Grp'] ==\"Upstream River\") & (ProfTest['Dam_Dist_km'] <= MisclassPoint)], x = 'Dam_Dist_km', y ='Avg_Temp',  linewidth= 2, color = \"#18A790\", label = \"Upstream River\")\n",
    "sns.lineplot(data = ProfTest[(ProfTest['Up_Ds_Grp'] ==\"Upstream Reservoir\")], x = 'Dam_Dist_km', y ='Avg_Temp', linewidth= 2, color = \"#1877A8\", label = \"Reservoir\")\n",
    "sns.lineplot(data = ProfTest[(ProfTest['Up_Ds_Grp'] ==\"Downstream River\")], x = 'Dam_Dist_km', y ='Avg_Temp', linewidth= 2, color = \"#1C4BC4\", label = \"Downstream River\")\n",
    "plt.xlim(-45,21)\n",
    "plt.hlines(y=ProfTest_Avg_up, xmin=(ProfTest[ProfTest['Up_Ds_Grp'] ==\"Upstream River\"].Dam_Dist_km.min()), xmax=MisclassPoint , linewidth=3, color='#7F0824', alpha = 0.8)\n",
    "plt.hlines(y=ProfTest_Avg_ds, xmin= 0, xmax= (ProfTest[ProfTest[\"Up_Ds_Grp\"]==\"Downstream River\"].Dam_Dist_km.max()), linewidth=3, color='#7F0824',alpha = 0.8, label = \"Average Temperature\")\n",
    "plt.axvline(x=0.1, linewidth=3, color='#fb5607', linestyle='--', zorder = 1, label = 'Dam')\n",
    "plt.xlabel(\"Distance Downstream (km)\", fontsize = 16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.ylabel(\"Water Surface Temperature (°C)\", fontsize = 16)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend([], [], frameon=False)\n",
    "plt.locator_params(axis='y', nbins= 6)\n",
    "plt.tight_layout()\n",
    "fig.savefig(r\"F:\\Insert_Path_for_Warmer_Profile_02152022.png\", bbox_inches=\"tight\", pad_inches=0.25, dpi=1200) # Update this file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### No Change Example ####\n",
    "# Set up the plot\n",
    "fig, ax=plt.subplots(figsize=(8,6))\n",
    "\n",
    "#  Get profile for Dam 306 on Dec. 21, 2024\n",
    "ProfTest = NS_Riv20_Profile_Nodes[(NS_Riv20_Profile_Nodes['Month'] == 12) & (NS_Riv20_Profile_Nodes['Day'] == 21) & (NS_Riv20_Profile_Nodes['Year'] == 2024) & (NS_Riv20_Profile_Nodes['Assgn_dam'] == 306)]\n",
    "ProfTest_Avg_up = ProfTest[ProfTest['Up_Ds_Grp'] == \"Upstream River\"].Avg_Temp.mean()\n",
    "ProfTest_Avg_ds = ProfTest[ProfTest['Up_Ds_Grp'] == \"Downstream River\"].Avg_Temp.mean()\n",
    "\n",
    "# Single spurious point, removed for visualization\n",
    "MisclassPoint = ProfTest[(ProfTest['Up_Ds_Grp'] ==\"Upstream Reservoir\")].Dam_Dist_km.min()\n",
    "\n",
    "# Plot\n",
    "sns.lineplot(data = ProfTest[(ProfTest['Up_Ds_Grp'] ==\"Upstream River\") & (ProfTest['Dam_Dist_km'] <= MisclassPoint)], x = 'Dam_Dist_km', y ='Avg_Temp',  linewidth= 2, color = \"#18A790\", label = \"Upstream River\")\n",
    "sns.lineplot(data = ProfTest[(ProfTest['Up_Ds_Grp'] ==\"Upstream Reservoir\")], x = 'Dam_Dist_km', y ='Avg_Temp', linewidth= 2, color = \"#1877A8\", label = \"Reservoir\")\n",
    "sns.lineplot(data = ProfTest[(ProfTest['Up_Ds_Grp'] ==\"Downstream River\")], x = 'Dam_Dist_km', y ='Avg_Temp', linewidth= 2, color = \"#1C4BC4\", label = \"Downstream River\")\n",
    "plt.xlim(-45,21)\n",
    "plt.hlines(y=ProfTest_Avg_up, xmin=(ProfTest[ProfTest['Up_Ds_Grp'] ==\"Upstream River\"].Dam_Dist_km.min()), xmax=MisclassPoint , linewidth=3, color='#7F0824', alpha = 0.8)\n",
    "plt.hlines(y=ProfTest_Avg_ds, xmin= 0, xmax= (ProfTest[ProfTest[\"Up_Ds_Grp\"]==\"Downstream River\"].Dam_Dist_km.max()), linewidth=3, color='#7F0824',alpha = 0.8, label = \"Average Temperature\")\n",
    "plt.axvline(x=0.1, linewidth=3, color='#fb5607', linestyle='--', zorder = 1, label = 'Dam')\n",
    "plt.xlabel(\"Distance Downstream (km)\", fontsize = 16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.ylabel(\"Water Surface Temperature (°C)\", fontsize = 16)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend([], [], frameon=False)\n",
    "plt.locator_params(axis='y', nbins= 6)\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(r\"F:\\Insert_Path_for_NoChange_Profile_12212024.png\", bbox_inches=\"tight\", pad_inches=0.25, dpi=1200)# Update this file path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "## Extra Profile Details ##\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the some Upstream Counts ##\n",
    "print(\"Median Upstream River length: \" + str(round(((UpAnDown.NodeCount_y.median() * 200)/1000))))\n",
    "print(\"Mean Upstream River length: \" + str(round(((UpAnDown.NodeCount_y.mean() * 200)/1000))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "## Compare the Observed Widths to Accuracy Assessment Widths ##\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Accuracy Assessment Comparision Graphics \n",
    "## Get the widths of nodes used in the analysis\n",
    "Profile_Nodes_widths = Profile_Differences[Profile_Differences['Dam_Dist_km'] <= 60]\n",
    "\n",
    "# Get Node Width Stats \n",
    "print(\"Median Landsat Observation Width: \", str(round(Profile_Nodes_widths[\"Avg_RWC_Wid\"].median())))\n",
    "\n",
    "# Pull in the widths at the gage locations \n",
    "AANodeWidths = pd.read_csv(r\"F:\\Insert_Path_for_Widths_AA.csv\") # Update this file path #Created during Accuracy Assessment\n",
    "JustAAWidths_df = pd.concat([AANodeWidths['Avg_RWC_Wid_x'], AANodeWidths['Avg_RWC_Wid_y']]).to_frame()\n",
    "JustAAWidths_df.columns = ['Width']\n",
    "JustAAWidths_df[\"NodeType\"] = \"USGS Gage Width\"\n",
    "print(\"Median Gage Observation Width: \", str(round(JustAAWidths_df[\"Width\"].median())))\n",
    "\n",
    "## Observation Widths\n",
    "Obvs_Widths = Profile_Nodes_widths[[\"Avg_RWC_Wid\"]]\n",
    "Obvs_Widths = Obvs_Widths.rename(columns={\"Avg_RWC_Wid\": \"Width\"})\n",
    "Obvs_Widths[\"NodeType\"] = \"Profile Node Width\"\n",
    "\n",
    "# Combine \n",
    "AllNodeWidths = pd.concat([JustAAWidths_df, Obvs_Widths], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the Widths \n",
    "# Set the plot details\n",
    "my_palette = ['#C1B3E3', '#fb5012']\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(6,2))\n",
    "ax = sns.boxplot(data=AllNodeWidths, x=\"Width\", hue =\"NodeType\", linecolor=\"#1A0E00\", linewidth=1.5, width=0.75, gap=0.25,  palette=my_palette, showfliers = False) # Comment this out to see outliers\n",
    "ax.set_xlim(75, 1000)\n",
    "ax.set_xlabel( \"River Width (m)\", fontsize=14) \n",
    "ax.set_title(\"Distribution of Observation Widths\", fontsize = 14)\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(100))\n",
    "ax.legend().set_title('')\n",
    "fig.savefig(r\"F:\\Insert_Path_for_All_Node_Widths.png\", bbox_inches=\"tight\", pad_inches=0.25, dpi=1200) # Update this file path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
